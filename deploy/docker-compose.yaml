services:

  api:
    image: nvcr.io/nvidia/blueprint/foundational-flywheel-server:${TAG:-0.3.0}
    build:
      context: ..
      dockerfile: ./deploy/Dockerfile
      target: dev
    ports:
      - "8000:8000"
    environment:
      - ELASTICSEARCH_URL=http://localhost:9200
      - ES_COLLECTION_NAME=${ES_COLLECTION_NAME:-flywheel}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme123}@localhost:6379/0
      - MONGODB_URL=mongodb://${MONGO_USERNAME:-admin}:${MONGO_PASSWORD:-changeme123}@localhost:27017
      - MONGODB_DB=flywheel
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - LLM_JUDGE_API_KEY=${LLM_JUDGE_API_KEY:-${NVIDIA_API_KEY}}
      - EMB_API_KEY=${EMB_API_KEY:-${NVIDIA_API_KEY}}
      - COMPOSE_PROFILES=${COMPOSE_PROFILES}
    volumes:
      - ./src:/app/src  # Mount the src directory for hot reloading
    command: ["uv", "run", "uvicorn", "src.app:app", "--host", "0.0.0.0", "--port", "8000"]
    network_mode: host
    restart: always
    depends_on:
      elasticsearch:
        condition: service_started
      redis:
        condition: service_started
      mongodb:
        condition: service_started

  celery_worker:
    image: nvcr.io/nvidia/blueprint/foundational-flywheel-server:${TAG:-0.3.0}
    build:
      context: ..
      dockerfile: ./deploy/Dockerfile
      target: dev
    environment:
      - ELASTICSEARCH_URL=http://localhost:9200
      - ES_COLLECTION_NAME=${ES_COLLECTION_NAME:-flywheel}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme123}@localhost:6379/0
      - MONGODB_URL=mongodb://${MONGO_USERNAME:-admin}:${MONGO_PASSWORD:-changeme123}@localhost:27017
      - MONGODB_DB=flywheel
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - LLM_JUDGE_API_KEY=${LLM_JUDGE_API_KEY:-${NVIDIA_API_KEY}}
      - EMB_API_KEY=${EMB_API_KEY:-${NVIDIA_API_KEY}}
      - COMPOSE_PROFILES=${COMPOSE_PROFILES}
    network_mode: host
    volumes:
      - ./src:/app/src  # Mount the src directory for hot reloading
    command: ["uv", "run", "celery", "-A", "src.tasks.cli:celery_app", "worker", "--loglevel=info", "--concurrency=50", "--queues=celery", "-n", "main_worker@%h", "--purge"]

    restart: always
    depends_on:
      elasticsearch:
        condition: service_started
      redis:
        condition: service_started
      mongodb:
        condition: service_started


  celery_parent_worker:
    image: nvcr.io/nvidia/blueprint/foundational-flywheel-server:${TAG:-0.3.0}
    build:
      context: ..
      dockerfile: ./deploy/Dockerfile
      target: dev
    environment:
      - ELASTICSEARCH_URL=http://localhost:9200
      - ES_COLLECTION_NAME=${ES_COLLECTION_NAME:-flywheel}
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme123}@localhost:6379/0
      - MONGODB_URL=mongodb://${MONGO_USERNAME:-admin}:${MONGO_PASSWORD:-changeme123}@localhost:27017
      - MONGODB_DB=flywheel
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - LLM_JUDGE_API_KEY=${LLM_JUDGE_API_KEY:-${NVIDIA_API_KEY}}
      - EMB_API_KEY=${EMB_API_KEY:-${NVIDIA_API_KEY}}
      - COMPOSE_PROFILES=${COMPOSE_PROFILES}
    network_mode: host
    volumes:
      - ./src:/app/src  # Mount the src directory for hot reloading
    command: ["uv", "run", "celery", "-A", "src.tasks.cli:celery_app", "worker", "--loglevel=info", "--concurrency=1", "--queues=parent_queue", "-n", "parent_worker@%h", "--purge"]

    restart: always
    depends_on:
      elasticsearch:
        condition: service_started
      redis:
        condition: service_started
      mongodb:
        condition: service_started


  # Datastores
  # - Redis is the Celery broker and result backend
  # - MongoDB is the database for the API
  # - Elasticsearch is the database for the logging proxy
  redis:
    image: redis:7.2-alpine
    ports:
      - "6379:6379"  # Bind to localhost only
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-changeme123}
    restart: always

  mongodb:
    image: mongo:7.0
    ports:
      - "27017:27017"  # Bind to localhost only
    volumes:
      - mongodb-data:/data/db
    environment:
      - MONGO_LOG_LEVEL=error
      - MONGO_INITDB_ROOT_USERNAME=${MONGO_USERNAME:-admin}
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASSWORD:-changeme123}
    command: >
      mongod --quiet --auth
      --setParameter diagnosticDataCollectionEnabled=false
      --setParameter logComponentVerbosity='{ "network": { "verbosity": 0 }, "command": { "verbosity": 0 }, "control": { "verbosity": 0 } }'
    restart: always
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet -u ${MONGO_USERNAME:-admin} -p ${MONGO_PASSWORD:-changeme123}
      interval: 10s
      timeout: 10s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.2
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - cluster.routing.allocation.disk.watermark.low=99%
      - cluster.routing.allocation.disk.watermark.high=99%
      - cluster.routing.allocation.disk.watermark.flood_stage=99%
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - logger.org.elasticsearch=ERROR
      - logger.org.elasticsearch.cluster=ERROR
      - logger.org.elasticsearch.discovery=ERROR
      - logger.org.elasticsearch.gateway=ERROR
      - logger.org.elasticsearch.indices=ERROR
      - logger.org.elasticsearch.node=ERROR
      - logger.org.elasticsearch.transport=ERROR
    ports:
      - "9200:9200"  # Bind to localhost only
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1

  # MLflow service - only starts when mlflow profile is enabled
  mlflow:
    profiles: ["mlflow"]
    image: ghcr.io/mlflow/mlflow:v2.22.0
    command: mlflow server --host 0.0.0.0 --port 5000
    ports:
      - "5000:5000"
    volumes:
      - mlflow-data:/mlruns  # Persistent storage for artifacts
    restart: always

volumes:
  elasticsearch-data:
  redis-data:
  mongodb-data:
  mlflow-data:
